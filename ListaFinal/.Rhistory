dp.bernoulli = sqrt(p*(1-p))
dp.bernoulli
dp.xbar.teorico = dp.bernoulli / sqrt(n.tamanho.amostral)
dp.xbar.teorico
# Comparado com:
desvio.xbar
# Gr?ficos das Simula??es
vetor.amostras.x.barra
hist(vetor.amostras.x.barra, freq = FALSE, ylab="Densidade",
col="pink",
main="Propor??es amostrais (n=100) de 1000 Inspe??es",
sub = "Com Curva da Normal Te?rica da Propor??o Amostral",
ylim=c(0,85),
xlim=c(-0.001, 0.057)
)
# Gr?fico da Distribui??o amostral da propor??o:
#Normal Te?rica (p, px(1-p)/n)
x = vetor.amostras.x.barra
curve(dnorm(x,mean=p, sd=dp.xbar.teorico),
from = min(vetor.amostras.x.barra),
to= max(vetor.amostras.x.barra),
add = T)
# Probabilidades
# 1) No m?ximo 2% pe?as defeituosas dentre 100 observadas equivale a
# no m?ximo 2 dentre 100
#P(P^barra <= 0.02) = P(X <= 2)
# P^barra ~ Normal e X ~ Binomial
?pbinom
# Probabilidade aproximada pela normal
pnorm(0.02, mean = p, sd = dp.xbar.teorico )
# Probabilidade exata usando a Binomial (2% do total)
quantil.x = 0.02 * n.tamanho.amostral
quantil.x
pbinom(quantil.x, size = n.tamanho.amostral, prob = p)
### Refa?a a Simula??o trabalhando com
# n.tamanho.amostral = 100 observa??es por amostra
# E fa?a compara??es de todos os resultados encontrados,
# inclusive as probabilidades. A aproxima??o da Binomial pela Normal
# continua boa? Por que?
# Compreender as fun??es:
?rnorm
?dnorm
?rbinom
# ==== Para a Binomial => Fa?am help: ====
?rbinom
# ====  Exemplo para vari?veis discretas: ====
# Ajuda Encontrado no site:
# https://rpubs.com/rcleoni/estdescritiva
dados.discretos = c(1,0,1,1) # Tr?s 1?s: Homens e Um 0: Mulher
# Tabelas de frequ?ncias absolutas e relativas
homens.tab.abs = table(dados.discretos)
homens.tab.abs
plot(homens.tab.abs) # Gr?fico para vari?veis discretas
# Acrescentando 'label' ?s categorias do objeto table
str(homens.tab.abs)
names(homens.tab.abs) = list('Mulher', 'Homem')
plot(homens.tab.abs,
xlab = 'G?nero',
ylab = 'Freq.') # Gr?fico para vari?veis discretas
homens.tab.rel = prop.table(homens.tab.abs)
homens.tab.rel
plot(homens.tab.rel,
xlab = 'G?nero',
ylab = '%',
ylim = c(0,1)) # Gr?fico para vari?veis discretas
# ==== Gr?fico de barras =====
# Ajuda tamb?m encontrada em:
# http://www.estatisticacomr.uff.br/wp-content/uploads/2018/10/Rgraficos.pdf
?barplot
# ==== Exemplo de X ~ Discreta [(0,0.1), (1,0.3), (2,0.5), (3,0.1)]
x = 0:3
probs = c(0.1, 0.3, 0.5, 0.1)
barplot(names=x, probs,
xlab='N?m. de Defeitos',
ylim=c(0,1),
#xlim = c(0,3),
#width = 0.3
)
# ==== Gr?fico Binomial =====
#    Encontrado no site:
# https://cran.r-project.org/doc/contrib/Itano-descriptive-stats.pdf
?rbinom
?points
n=10; p=0.25
# Gera/Simula 100 dados de X ~ Binomial(n=10, p=0.25)
x=rbinom(100,n,p)
x
hist(x, probability=TRUE, ylab="Densidade",
col="pink",
main="Binomial",
ylim=c(0,0.40),
xlim=c(0,10))
# Gr?fico da Distribui??o Binomial Te?rica: Binomial(n=10, p=0.25)
xvalores=0:n
xvalores
points(xvalores,
dbinom(xvalores,n,p),
type="h",
lwd=3)
points(xvalores,
dbinom(xvalores,n,p),
type="p",
lwd=3)
###########  EXERC?CIO DE SIMULA??O PARA OBSERVAR A APROXIMA??O
###########           DA BINOMIAL PELA NORMAL
# ===== Simula??o para um Distribui??o amostral da propor??o
#       (m?dia quando a popula??o ? Bernoulli)
k.amostras = 1000
n.tamanho.amostral = 1000  # Fazer com 100
n = 1     # n = 1 n?mero de repeti??es na Binomial equivale a uma Bernoulli
p = 0.01  # Probabilidade de sucesso de 1% pode estar associado
#a um evento raro
# PESQUISEM E OU LEIAM NO LIVRO do Larson (Texto da disciplina) sobre
#como aproximar uma binomial pela normal tamb?m
#Observe Condi??es para uma boa aproxima??o:
# com n.tamanho.amostral = ?, tem-se
valor.esperado.binomial = n.tamanho.amostral * p
valor.esperado.binomial
segunda.condicao.binomial.pela.normal = n.tamanho.amostral * (1-p)
segunda.condicao.binomial.pela.normal
#  Gerando dados/propor??es amostrais:
# k.amostras de tamanho n.tamanho.amostral (n.tamanho.amostral Bernoullis)
vetor.amostras.x.barra = c()
for (i in 1:k.amostras) {
x.bernoullis = rbinom(n.tamanho.amostral, n, p)
vetor.amostras.x.barra[i] = mean(x.bernoullis)
}
media.xbar  = mean(vetor.amostras.x.barra)
desvio.xbar = sd(vetor.amostras.x.barra)
# Verificando
media.xbar
desvio.xbar
# Obs: Te?ricamente:
# media.xbar = 0,0097 aprox = m?dia da popula??o = 0,01
# desvio.xbar = dp.bernoulli / raiz(n) = 0.099 / raiz(100) = 0.009
dp.bernoulli = sqrt(p*(1-p))
dp.bernoulli
dp.xbar.teorico = dp.bernoulli / sqrt(n.tamanho.amostral)
dp.xbar.teorico
# Comparado com:
desvio.xbar
# Gr?ficos das Simula??es
vetor.amostras.x.barra
hist(vetor.amostras.x.barra, freq = FALSE, ylab="Densidade",
col="pink",
main="Propor??es amostrais (n=100) de 1000 Inspe??es",
sub = "Com Curva da Normal Te?rica da Propor??o Amostral",
ylim=c(0,85),
xlim=c(-0.001, 0.057)
)
# Gr?fico da Distribui??o amostral da propor??o:
#Normal Te?rica (p, px(1-p)/n)
x = vetor.amostras.x.barra
curve(dnorm(x,mean=p, sd=dp.xbar.teorico),
from = min(vetor.amostras.x.barra),
to= max(vetor.amostras.x.barra),
add = T)
# Probabilidades
# 1) No m?ximo 2% pe?as defeituosas dentre 100 observadas equivale a
# no m?ximo 2 dentre 100
#P(P^barra <= 0.02) = P(X <= 2)
# P^barra ~ Normal e X ~ Binomial
?pbinom
# Probabilidade aproximada pela normal
pnorm(0.02, mean = p, sd = dp.xbar.teorico )
# Probabilidade exata usando a Binomial (2% do total)
quantil.x = 0.02 * n.tamanho.amostral
quantil.x
pbinom(quantil.x, size = n.tamanho.amostral, prob = p)
### Refa?a a Simula??o trabalhando com
# n.tamanho.amostral = 100 observa??es por amostra
# E fa?a compara??es de todos os resultados encontrados,
# inclusive as probabilidades. A aproxima??o da Binomial pela Normal
# continua boa? Por que?
# ==== Exemplo de X ~ Discreta [(0,0.1), (1,0.3), (2,0.5), (3,0.1)]
x = 0:3
probs = c(0.1, 0.3, 0.5, 0.1)
barplot(names=x, probs,
xlab='N?m. de Defeitos',
ylim=c(0,1),
#xlim = c(0,3),
#width = 0.3
)
?barplot
#importando bibliotecas que serao usadas nessa questao
library(ggplot2)
#9.2
# A base de dados usada eh disponibilizada pelo US Departament of Energy e contem basicamente as
# informacoes de diversos carros e suas caracteristicas como milhas por galao (mpg), tamanho do motor,
# tipo da injecao, quantidade de cilindros, etc.
# link para acessar mais base de dados como essa: https://www.fueleconomy.gov/feg/download.shtml
carros2018 <- read.csv("cars2018.csv")
#settando diretorio de trabalho (Que muda de acordo com a maquina em que esse codigo estiver rodando)
setwd("./ListaFinal")
#9.2
# A base de dados usada eh disponibilizada pelo US Departament of Energy e contem basicamente as
# informacoes de diversos carros e suas caracteristicas como milhas por galao (mpg), tamanho do motor,
# tipo da injecao, quantidade de cilindros, etc.
# link para acessar mais base de dados como essa: https://www.fueleconomy.gov/feg/download.shtml
carros2018 <- read.csv("cars2018.csv")
#9.2
# A base de dados usada eh disponibilizada pelo US Departament of Energy e contem basicamente as
# informacoes de diversos carros e suas caracteristicas como milhas por galao (mpg), tamanho do motor,
# tipo da injecao, quantidade de cilindros, etc.
# link para acessar mais base de dados como essa: https://www.fueleconomy.gov/feg/download.shtml
carros2018 <- read.csv("./cars2018.csv")
?select
library(tidyverse)
install.packages("tidyverse")
#install.packages("tidyverse")
library(tidyverse)
#install.packages("tidyverse")
library(tidyverse)
#settando diretorio de trabalho (Que muda de acordo com a maquina em que esse codigo estiver rodando)
setwd("./Downloads/Estatistica/ListaFinal")
#9.2
# A base de dados usada eh disponibilizada pelo US Departament of Energy e contem basicamente as
# informacoes de diversos carros e suas caracteristicas como milhas por galao (mpg), tamanho do motor,
# tipo da injecao, quantidade de cilindros, etc.
# link para acessar mais base de dados como essa: https://www.fueleconomy.gov/feg/download.shtml
carros2018 <- read.csv("cars2018.csv")
\quit
quit
#9.2
# A base de dados usada eh disponibilizada pelo US Departament of Energy e contem basicamente as
# informacoes de diversos carros e suas caracteristicas como milhas por galao (mpg), tamanho do motor,
# tipo da injecao, quantidade de cilindros, etc.
# link para acessar mais base de dados como essa: https://www.fueleconomy.gov/feg/download.shtml
carros2018 <- read.csv("cars2018.csv")
# Dando uma pequena olhada em como os dados estao dispostos
glimpse(carros2018)
# Nessa grafico de dispercao observamos que existe uma correlacao linear negativa entre displacement e mpg.
# O que se pode dizer nessa analise eh que quanto maior a acelaracao do carro, mais ele gasta combustivel.
plot <- ggplot(carros2018)
plot + geom_point(aes(x = displacement, y = mpg))
# A base de dados escolhida para trabalho envolve outras 12 variaveis, mas como o objeto de estudo eh
# correlacao linear simples, iremos considerar apenas duas variaveis desse data frame, que sao as mesmas
# analisadas no plot acima.
mpg <- array(unlist(carros2018 %>% select(mpg)))
displacement <- array(unlist(carros2018 %>% select(displacement)))
rm(plot, carros2018)
#analise descritiva da variavel dependente
summary(mpg)
#analise descritiva da variavel independente
summary(displacement)
#9.2 b)
# Aqui calculamos com a funcao cor o coeficiente de correlacao linear entre essas duas variaveis. Como
# analisado anteriormente, temos uma correlacao negativa e por termos diversos pontos atipicos, a correlacao
# nao eh tao forte
cor(displacement, mpg)
#9.2 c)
#Realizando analise de regressao simples.
#A execucao do comando lm(displacement~mpg) retorna o valor dos coeficientes de β0 e β1 estimados via Metodo de
# Minimos Quadrado.
#Logo, a equação da reta ajustada é dada por Y = 7.1550 - 0.17514Xi
fit = lm(displacement~mpg)
fit
# A chamada summary(fit) gera resultados como erro padrao (std.error) das estimativas dos coeficientes de regressao
#EP(β0) = 0.112219 e EP(β1) = 0.004704. Alem disso temos o valor do coeficiente de determinacao (multiple R squared).
summary(fit)
# Realizando teste de hipotese
cor.test(displacement, mpg)
# Como o Valor P do teste (p-value < 2.2e-16) é bem pequeno, conclui-se que o valor do Coeficiente de Correlação Linear
# Como o Valor P do teste (p-value < 2.2e-16) é bem pequeno, conclui-se que o valor do Coeficiente de Correlação Linear
# de Pearson tem certa significância Estatística.
# Como o Valor P do teste (p-value < 2.2e-16) é bem pequeno, conclui-se que o valor do Coeficiente de Correlação Linear
# de Pearson tem certa significância Estatística.
# Como o Valor P do teste (p-value < 2.2e-16) é bem pequeno, conclui-se que o valor do Coeficiente de Correlação Linear
# de Pearson tem certa significância Estatística.
# Como o Valor P do teste (p-value < 2.2e-16) é bem pequeno, conclui-se que o valor do Coeficiente de Correlação Linear
# de Pearson tem certa significância Estatística.
# Como o Valor P do teste (p-value < 2.2e-16) é bem pequeno, conclui-se que o valor do Coeficiente de Correlação Linear
# de Pearson tem certa significância Estatística.
# Como o Valor P do teste (p-value < 2.2e-16) é bem pequeno, conclui-se que o valor do Coeficiente de Correlação Linear
# de Pearson tem certa significância Estatística.
# Como o Valor P do teste (p-value < 2.2e-16) é bem pequeno, conclui-se que o valor do Coeficiente de Correlação Linear
# de Pearson tem certa significância Estatística.
# Como o Valor P do teste (p-value < 2.2e-16) é bem pequeno, conclui-se que o valor do Coeficiente de Correlação Linear
# de Pearson tem certa significância Estatística.
# Como o Valor P do teste (p-value < 2.2e-16) é bem pequeno, conclui-se que o valor do Coeficiente de Correlação Linear
# de Pearson tem certa significância Estatística.
# Como o Valor P do teste (p-value < 2.2e-16) é bem pequeno, conclui-se que o valor do Coeficiente de Correlação Linear
# de Pearson tem certa significância Estatística.
# Como o Valor P do teste (p-value < 2.2e-16) é bem pequeno, conclui-se que o valor do Coeficiente de Correlação Linear
# de Pearson tem certa significância Estatística.
# Como o Valor P do teste (p-value < 2.2e-16) é bem pequeno, conclui-se que o valor do Coeficiente de Correlação Linear
# de Pearson tem certa significância Estatística.
# Como o Valor P do teste (p-value < 2.2e-16) é bem pequeno, conclui-se que o valor do Coeficiente de Correlação Linear
# de Pearson tem certa significância Estatística.
# Como o Valor P do teste (p-value < 2.2e-16) é bem pequeno, conclui-se que o valor do Coeficiente de Correlação Linear
# de Pearson tem certa significância Estatística.
# Como o Valor P do teste (p-value < 2.2e-16) é bem pequeno, conclui-se que o valor do Coeficiente de Correlação Linear
# de Pearson tem certa significância Estatística.
# Como o Valor P do teste (p-value < 2.2e-16) é bem pequeno, conclui-se que o valor do Coeficiente de Correlação Linear
# de Pearson tem certa significância Estatística.
# Como o Valor P do teste (p-value < 2.2e-16) é bem pequeno, conclui-se que o valor do Coeficiente de Correlação Linear
# de Pearson tem certa significância Estatística.
# Como o Valor P do teste (p-value < 2.2e-16) é bem pequeno, conclui-se que o valor do Coeficiente de Correlação Linear
# de Pearson tem certa significância Estatística.
# Como o Valor P do teste (p-value < 2.2e-16) é bem pequeno, conclui-se que o valor do Coeficiente de Correlação Linear
# de Pearson tem certa significância Estatística.
# Como o Valor P do teste (p-value < 2.2e-16) é bem pequeno, conclui-se que o valor do Coeficiente de Correlação Linear
# de Pearson tem certa significância Estatística.
# Como o Valor P do teste (p-value < 2.2e-16) é bem pequeno, conclui-se que o valor do Coeficiente de Correlação Linear
# de Pearson tem certa significância Estatística.
p
p
p
p
p
p
p
#install.packages("tidyverse")
library(tidyverse)
#settando diretorio de trabalho (Que muda de acordo com a maquina em que esse codigo estiver rodando)
setwd("./Downloads/Estatistica/ListaFinal")
#9.2
# A base de dados usada eh disponibilizada pelo US Departament of Energy e contem basicamente as
# informacoes de diversos carros e suas caracteristicas como milhas por galao (mpg), tamanho do motor,
# tipo da injecao, quantidade de cilindros, etc.
# link para acessar mais base de dados como essa: https://www.fueleconomy.gov/feg/download.shtml
carros2018 <- read.csv("cars2018.csv")
# Dando uma pequena olhada em como os dados estao dispostos
glimpse(carros2018)
# Nessa grafico de dispercao observamos que existe uma correlacao linear negativa entre displacement e mpg.
# O que se pode dizer nessa analise eh que quanto maior a acelaracao do carro, mais ele gasta combustivel.
plot <- ggplot(carros2018)
plot + geom_point(aes(x = displacement, y = mpg))
# A base de dados escolhida para trabalho envolve outras 12 variaveis, mas como o objeto de estudo eh
# correlacao linear simples, iremos considerar apenas duas variaveis desse data frame, que sao as mesmas
# analisadas no plot acima.
mpg <- array(unlist(carros2018 %>% select(mpg)))
displacement <- array(unlist(carros2018 %>% select(displacement)))
rm(plot, carros2018)
#analise descritiva da variavel dependente
summary(mpg)
#analise descritiva da variavel independente
summary(displacement)
#9.2 b)
# Aqui calculamos com a funcao cor o coeficiente de correlacao linear entre essas duas variaveis. Como
# analisado anteriormente, temos uma correlacao negativa e por termos diversos pontos atipicos, a correlacao
# nao eh tao forte
cor(displacement, mpg)
#9.2 c)
#Realizando analise de regressao simples.
#A execucao do comando lm(displacement~mpg) retorna o valor dos coeficientes de β0 e β1 estimados via Metodo de
# Minimos Quadrado.
#Logo, a equação da reta ajustada é dada por Y = 7.1550 - 0.17514Xi
fit = lm(displacement~mpg)
fit
# A chamada summary(fit) gera resultados como erro padrao (std.error) das estimativas dos coeficientes de regressao
#EP(β0) = 0.112219 e EP(β1) = 0.004704. Alem disso temos o valor do coeficiente de determinacao (multiple R squared).
summary(fit)
# Realizando teste de hipotese
cor.test(displacement, mpg)
# Como o Valor P do teste (p-value < 2.2e-16) é bem pequeno, conclui-se que o valor do Coeficiente de Correlação Linear
# Como o Valor P do teste (p-value < 2.2e-16) é bem pequeno, conclui-se que o valor do Coeficiente de Correlação Linear
install.packages("tidyverse")
#install.packages("tidyverse")
library(tidyverse)
#9.2
# A base de dados usada eh disponibilizada pelo US Departament of Energy e contem basicamente as
# informacoes de diversos carros e suas caracteristicas como milhas por galao (mpg), tamanho do motor,
# tipo da injecao, quantidade de cilindros, etc.
# link para acessar mais base de dados como essa: https://www.fueleconomy.gov/feg/download.shtml
carros2018 <- read.csv("cars2018.csv")
# Dando uma pequena olhada em como os dados estao dispostos
glimpse(carros2018)
# ------------------------------------------ Questão 9 ----------------------------------------------
#importando bibliotecas que serao usadas nessa questao
library(ggplot2)
#install.packages("tidyverse")
library(tidyverse)
#settando diretorio de trabalho (Que muda de acordo com a maquina em que esse codigo estiver rodando)
setwd("./Downloads/Estatistica/ListaFinal")
#9.2
# A base de dados usada eh disponibilizada pelo US Departament of Energy e contem basicamente as
# informacoes de diversos carros e suas caracteristicas como milhas por galao (mpg), tamanho do motor,
# tipo da injecao, quantidade de cilindros, etc.
# link para acessar mais base de dados como essa: https://www.fueleconomy.gov/feg/download.shtml
carros2018 <- read.csv("cars2018.csv")
# Dando uma pequena olhada em como os dados estao dispostos
glimpse(carros2018)
#9.2 a)
# A variavel continua escolhida para o estudo eh o mpg(milhas por galao) dos carros. Queremos observar
#quais outras variaveis influenciam na eficiencia do gasto de combustivel.
# MPG: variavel dependente
# Nessa grafico de dispercao observamos que existe uma correlacao linear negativa entre displacement e mpg.
# O que se pode dizer nessa analise eh que quanto maior a acelaracao do carro, mais ele gasta combustivel.
plot <- ggplot(carros2018)
plot + geom_point(aes(x = displacement, y = mpg))
# A base de dados escolhida para trabalho envolve outras 12 variaveis, mas como o objeto de estudo eh
# correlacao linear simples, iremos considerar apenas duas variaveis desse data frame, que sao as mesmas
# analisadas no plot acima.
mpg <- array(unlist(carros2018 %>% select(mpg)))
displacement <- array(unlist(carros2018 %>% select(displacement)))
rm(plot, carros2018)
#analise descritiva da variavel dependente
summary(mpg)
#analise descritiva da variavel independente
summary(displacement)
#9.2 b)
# Aqui calculamos com a funcao cor o coeficiente de correlacao linear entre essas duas variaveis. Como
# analisado anteriormente, temos uma correlacao negativa e por termos diversos pontos atipicos, a correlacao
# nao eh tao forte
cor(displacement, mpg)
#9.2 c)
#Realizando analise de regressao simples.
#A execucao do comando lm(displacement~mpg) retorna o valor dos coeficientes de β0 e β1 estimados via Metodo de
# Minimos Quadrado.
#Logo, a equação da reta ajustada é dada por Y = 7.1550 - 0.17514Xi
fit = lm(displacement~mpg)
fit
# A chamada summary(fit) gera resultados como erro padrao (std.error) das estimativas dos coeficientes de regressao
#EP(β0) = 0.112219 e EP(β1) = 0.004704. Alem disso temos o valor do coeficiente de determinacao (multiple R squared).
summary(fit)
# Realizando teste de hipotese
cor.test(displacement, mpg)
# Como o Valor P do teste (p-value < 2.2e-16) é bem pequeno, conclui-se que o valor do Coeficiente de Correlação Linear
# de Pearson tem certa significância Estatística.
install.packages("tidyverse")
install.packages("tidyverse")
# instalando e utilizando bibliotecas necessárias
install.packages("tidyverse")
library(tidyverse)
library(ggplot2)
# informando o local onde está a base de dados
# DEVE-SE ALTERAR AO MUDAR DE COMPUTADOR!!!
setwd("C:/Users/Higor/Desktop/Estatística/Prova")
# realizando a leitura dos dados
dados = read.csv("02_Dados_Amamentacao_Cancer.csv")
# buscando os dados da coluna referente ao cancer
cancer = array(unlist(dados %>% select(cancer)))
# analisando as métricas da coluna
summary(cancer)
# buscando os dados da coluna referente à amamentação
amamentacao = array(unlist(dados %>% select(amamentacao)))
# analisando as métricas da coluna
summary(amamentacao)
# a planilha completa já não é mais necessária então pode ser removida
remove(dados)
# gerando uma tabela com os dados obtidos da planilha
dados.table = table(cancer, amamentacao)
dados.table
# Realizando os testes
# Inicialmente, realizando o teste Qui-quadrado de Pearson com a tabela
# gerada
chisq.test(dados.table, correct = TRUE)
# foi obtido um p-valor de 0.005268, o que dá indícios de uma associação
# entre as duas variáveis
# Agora, realizando um teste de igualdade entre as proporções
prop.test(dados.table, correct = TRUE, alternative = "two.sided")
# Foi obtido um p-valor igual o anterior, e os valores das estimativas foram:
# 0.2541528 e 0.3314394, onde a diferença de valor é diferente de 0.
# Portanto, o fato de amamentar é um fator de proteção para o câncer
# de mama.
# instalando e utilizando bibliotecas necessárias
install.packages("tidyverse")
library(tidyverse)
library(ggplot2)
# informando o local onde está a base de dados
# DEVE-SE ALTERAR AO MUDAR DE COMPUTADOR!!!
setwd("./Downloads/Estatistica/ListaFinal")
# realizando a leitura dos dados
dados = read.csv("02_Dados_Amamentacao_Cancer.csv")
# buscando os dados da coluna referente ao cancer
cancer = array(unlist(dados %>% select(cancer)))
# analisando as métricas da coluna
summary(cancer)
# buscando os dados da coluna referente à amamentação
amamentacao = array(unlist(dados %>% select(amamentacao)))
# analisando as métricas da coluna
summary(amamentacao)
# a planilha completa já não é mais necessária então pode ser removida
remove(dados)
# gerando uma tabela com os dados obtidos da planilha
dados.table = table(cancer, amamentacao)
dados.table
# Realizando os testes
# Inicialmente, realizando o teste Qui-quadrado de Pearson com a tabela
# gerada
chisq.test(dados.table, correct = TRUE)
# foi obtido um p-valor de 0.005268, o que dá indícios de uma associação
# entre as duas variáveis
# Agora, realizando um teste de igualdade entre as proporções
prop.test(dados.table, correct = TRUE, alternative = "two.sided")
# Foi obtido um p-valor igual o anterior, e os valores das estimativas foram:
# 0.2541528 e 0.3314394, onde a diferença de valor é diferente de 0.
# Portanto, o fato de amamentar é um fator de proteção para o câncer
# de mama.
library(tidyverse)
library(ggplot2)
library(ggplot2)
# informando o local onde está a base de dados
# DEVE-SE ALTERAR AO MUDAR DE COMPUTADOR!!!
setwd("./Downloads/Estatistica/ListaFinal")
# realizando a leitura dos dados
dados = read.csv("02_Dados_Amamentacao_Cancer.csv")
# buscando os dados da coluna referente ao cancer
cancer = array(unlist(dados %>% select(cancer)))
# analisando as métricas da coluna
summary(cancer)
# buscando os dados da coluna referente à amamentação
amamentacao = array(unlist(dados %>% select(amamentacao)))
# analisando as métricas da coluna
summary(amamentacao)
# a planilha completa já não é mais necessária então pode ser removida
remove(dados)
# gerando uma tabela com os dados obtidos da planilha
dados.table = table(cancer, amamentacao)
dados.table
install.packages("tidyverse")
